{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from mamba_ssm.models.mixer_seq_simple import MambaLMHeadModel\n",
    "from io import BytesIO\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import easydict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange, repeat\n",
    "from mamba_ssm.ops.selective_scan_interface import selective_scan_fn, mamba_inner_fn\n",
    "try:\n",
    "    from causal_conv1d import causal_conv1d_fn, causal_conv1d_update\n",
    "except ImportError:\n",
    "    causal_conv1d_fn, causal_conv1d_update = None\n",
    "try:\n",
    "    from mamba_ssm.ops.triton.layernorm import RMSNorm, layer_norm_fn, rms_norm_fn\n",
    "except ImportError:\n",
    "    RMSNorm, layer_norm_fn, rms_norm_fn = None, None, None\n",
    "import gc\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_param', type=str, default='130m')\n",
    "parser.add_argument('--model_address', type=str, default='./mamba_ssm/models/state-spaces_mamba-130m/')\n",
    "parser.add_argument('--store_address', type=str, default='./mamba_ssm/models/test/')\n",
    "parser.add_argument('--seed', type=int, default=0)\n",
    "parser.add_argument('--nsamples',type=int, default=64)\n",
    "parser.add_argument('--seqlen', type=int, default=2048)\n",
    "parser.add_argument('--prune_in_proj', type=bool, default= True)\n",
    "parser.add_argument('--prune_conv1d',type= bool, default= True)\n",
    "parser.add_argument('--prune_x_proj',type= bool, default= True)\n",
    "parser.add_argument('--prune_dt_proj',type= bool, default= True)\n",
    "parser.add_argument('--prune_A_log',type= bool, default= False)\n",
    "parser.add_argument('--prune_out_proj',type= bool, default= True)\n",
    "parser.add_argument('--sparsity_ratio',type=float, default= 0.5)\n",
    "parser.add_argument('--device_num', type= str, default=\"cuda:0\")\n",
    "parser.add_argument('--type', type=str, default=\"float32\")\n",
    "parser.add_argument('--prune_n', type=int, default=0)\n",
    "\n",
    "args = parser.parse_args([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param = args.model_param\n",
    "prune_in_proj = args.prune_in_proj\n",
    "prune_conv1d = args.prune_conv1d\n",
    "prune_x_proj = args.prune_x_proj\n",
    "prune_dt_proj = args.prune_dt_proj\n",
    "prune_A_log = args.prune_A_log\n",
    "prune_out_proj = args.prune_out_proj\n",
    "seed = args.seed\n",
    "nsamples = args.nsamples\n",
    "seqlen = args.seqlen\n",
    "ssm_state = None\n",
    "sparsity_ratio = args.sparsity_ratio\n",
    "device_num = args.device_num\n",
    "prune_n = args.prune_n\n",
    "type = args.type\n",
    "\n",
    "if type == \"float32\":\n",
    "    dtype = torch.float32\n",
    "elif type == \"bfloat16\":\n",
    "    dtype = torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "\n",
    "class TokenizerWrapper:\n",
    "    def __init__(self, input_ids):\n",
    "        self.input_ids = input_ids\n",
    "\n",
    "# Load and process c4 dataset\n",
    "def get_c4(nsamples, seed, seqlen, tokenizer):\n",
    "    # Load train and validation datasets\n",
    "    traindata = load_dataset('allenai/c4', data_files={'train': 'en/c4-train.00000-of-01024.json.gz'}, split='train')\n",
    "    valdata = load_dataset('allenai/c4', data_files={'validation': 'en/c4-validation.00000-of-00008.json.gz'}, split='validation')\n",
    "\n",
    "    # Generate samples from training set\n",
    "    random.seed(seed)\n",
    "    trainloader = torch.LongTensor([])\n",
    "    for _ in range(nsamples):\n",
    "        while True:\n",
    "            i = random.randint(0, len(traindata) - 1)\n",
    "            trainenc = tokenizer(traindata[i]['text'], return_tensors='pt')\n",
    "            if trainenc.input_ids.shape[1] > seqlen:\n",
    "                break\n",
    "        i = random.randint(0, trainenc.input_ids.shape[1] - seqlen - 1)\n",
    "        j = i + seqlen\n",
    "        inp = trainenc.input_ids[:, i:j]\n",
    "        trainloader = torch.cat((trainloader, inp), dim=0)\n",
    "\n",
    "    # Prepare validation dataset\n",
    "    valenc = tokenizer(' '.join(valdata[:1100]['text']), return_tensors='pt')\n",
    "    valenc = valenc.input_ids[:, :(256 * seqlen)]\n",
    "    valenc = TokenizerWrapper(valenc)\n",
    "    return trainloader, valenc\n",
    "\n",
    "# Function to select the appropriate loader based on dataset name\n",
    "def get_loaders(name, nsamples=128, seed=0, seqlen=2048, tokenizer=None):\n",
    "    if \"c4\" in name:\n",
    "        return get_c4(nsamples, seed, seqlen, tokenizer)\n",
    "    \n",
    "def wanda(input_tensor, weight_tensor, sparsity_ratio, prune_n):\n",
    "    prune_m = prune_n * 2\n",
    "\n",
    "    result_tensor = weight_tensor\n",
    "    \n",
    "    l2_norm_tensor = torch.norm(input_tensor, p=2, dim=0) / input_tensor.shape[0]\n",
    "\n",
    "    l2_norm_tensor = l2_norm_tensor.unsqueeze(1).expand_as(weight_tensor.T)\n",
    "\n",
    "    wanda_tensor = torch.abs(weight_tensor) * l2_norm_tensor.T\n",
    "\n",
    "    if prune_n != 0:\n",
    "        weight_mask = (torch.zeros_like(wanda_tensor)==1)\n",
    "        for ii in range(wanda_tensor.shape[1]):\n",
    "            if ii % prune_m == 0:\n",
    "                tmp = wanda_tensor[:,ii:(ii+4)].float()\n",
    "                weight_mask.scatter_(1,ii+torch.topk(tmp, 2, dim=1, largest= False)[1], True) #smallest in tmp만 출력한다! [0]은 숫자 [1]은 위치를 나타낸다!\n",
    "    else:\n",
    "        thresh = torch.sort(wanda_tensor.flatten().cuda())[0][int(wanda_tensor.numel()*sparsity_ratio)].cpu()\n",
    "        weight_mask = (wanda_tensor<=thresh)\n",
    "    \n",
    "\n",
    "    result_tensor[weight_mask] = 0\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return result_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wanda_A(l2_norm_tensor, weight_tensor, sparsity_ratio, prune_n):\n",
    "    prune_m = prune_n * 2\n",
    "\n",
    "    result_tensor = weight_tensor\n",
    "\n",
    "    l2_norm_tensor = l2_norm_tensor ** (1/2)\n",
    "\n",
    "    wanda_tensor = torch.abs(weight_tensor) * l2_norm_tensor\n",
    "\n",
    "    if prune_n != 0:\n",
    "        weight_mask = (torch.zeros_like(wanda_tensor)==1)\n",
    "        for ii in range(wanda_tensor.shape[1]):\n",
    "            if ii % prune_m == 0:\n",
    "                tmp = wanda_tensor[:,ii:(ii+4)].float()\n",
    "                weight_mask.scatter_(1,ii+torch.topk(tmp, 2, dim=1, largest= False)[1], True) #smallest in tmp만 출력한다! [0]은 숫자 [1]은 위치를 나타낸다!\n",
    "    else:\n",
    "        thresh = torch.sort(wanda_tensor.flatten().cuda())[0][int(wanda_tensor.numel()*sparsity_ratio)].cpu()\n",
    "        weight_mask = (wanda_tensor<=thresh)\n",
    "    \n",
    "\n",
    "    result_tensor[weight_mask] = 0\n",
    "\n",
    "    # gc.collect()\n",
    "    # torch.cuda.empty_cache()\n",
    "    return result_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selective_scan_ref(u, delta, A, B, C, D=None, z=None, delta_bias=None, delta_softplus=False,\n",
    "                      return_last_state=False):\n",
    "    \"\"\"\n",
    "    u: r(B D L)\n",
    "    delta: r(B D L)\n",
    "    A: c(D N) or r(D N)\n",
    "    B: c(D N) or r(B N L) or r(B N 2L) or r(B G N L) or (B G N L)\n",
    "    C: c(D N) or r(B N L) or r(B N 2L) or r(B G N L) or (B G N L)\n",
    "    D: r(D)\n",
    "    z: r(B D L)\n",
    "    delta_bias: r(D), fp32\n",
    "\n",
    "    out: r(B D L)\n",
    "    last_state (optional): r(B D dstate) or c(B D dstate)\n",
    "    \"\"\"\n",
    "    dtype_in = u.dtype\n",
    "    u = u.float()\n",
    "    delta = delta.float()\n",
    "    if delta_bias is not None:\n",
    "        delta = delta + delta_bias[..., None].float()\n",
    "    if delta_softplus:\n",
    "        delta = F.softplus(delta)\n",
    "    batch, dim, dstate = u.shape[0], A.shape[0], A.shape[1]\n",
    "    is_variable_B = B.dim() >= 3\n",
    "    is_variable_C = C.dim() >= 3\n",
    "    if A.is_complex():\n",
    "        if is_variable_B:\n",
    "            B = torch.view_as_complex(rearrange(B.float(), \"... (L two) -> ... L two\", two=2))\n",
    "        if is_variable_C:\n",
    "            C = torch.view_as_complex(rearrange(C.float(), \"... (L two) -> ... L two\", two=2))\n",
    "    else:\n",
    "        B = B.float()\n",
    "        C = C.float()\n",
    "    x = A.new_zeros((batch, dim, dstate))\n",
    "    ys = []\n",
    "    deltaA = torch.exp(torch.einsum('bdl,dn->bdln', delta, A))\n",
    "    if not is_variable_B:\n",
    "        deltaB_u = torch.einsum('bdl,dn,bdl->bdln', delta, B, u)\n",
    "    else:\n",
    "        if B.dim() == 3:\n",
    "            deltaB_u = torch.einsum('bdl,bnl,bdl->bdln', delta, B, u)\n",
    "        else:\n",
    "            B = repeat(B, \"B G N L -> B (G H) N L\", H=dim // B.shape[1])\n",
    "            deltaB_u = torch.einsum('bdl,bdnl,bdl->bdln', delta, B, u)\n",
    "    if is_variable_C and C.dim() == 4:\n",
    "        C = repeat(C, \"B G N L -> B (G H) N L\", H=dim // C.shape[1])\n",
    "    last_state = None\n",
    "    for i in range(u.shape[2]):\n",
    "        x = deltaA[:, :, i] * x + deltaB_u[:, :, i]\n",
    "        print(x)\n",
    "        print(x.shape)\n",
    "        if not is_variable_C:\n",
    "            y = torch.einsum('bdn,dn->bd', x, C)\n",
    "        else:\n",
    "            if C.dim() == 3:\n",
    "                y = torch.einsum('bdn,bn->bd', x, C[:, :, i])\n",
    "            else:\n",
    "                y = torch.einsum('bdn,bdn->bd', x, C[:, :, :, i])\n",
    "        if i == u.shape[2] - 1:\n",
    "            last_state = x\n",
    "        if y.is_complex():\n",
    "            y = y.real * 2\n",
    "        ys.append(y)\n",
    "    y = torch.stack(ys, dim=2) # (batch dim L)\n",
    "    out = y if D is None else y + u * rearrange(D, \"d -> d 1\")\n",
    "    if z is not None:\n",
    "        out = out * F.silu(z)\n",
    "    out = out.to(dtype=dtype_in)\n",
    "    return out if not return_last_state else (out, last_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./mamba_ssm/models/state-spaces_mamba-130m/\n"
     ]
    }
   ],
   "source": [
    "print(os.path.expanduser(args.model_address))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "model = MambaLMHeadModel.from_pretrained(os.path.expanduser(args.model_address), device=device_num, dtype=dtype)\n",
    "device = torch.device(device_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading calibdation data\n",
      "dataset loading complete\n"
     ]
    }
   ],
   "source": [
    "#c4 dataset 불러오기\n",
    "print(\"loading calibdation data\")\n",
    "dataloader, _ = get_loaders(\"c4\",nsamples=nsamples,seed=args.seed,seqlen=2048,tokenizer=tokenizer)\n",
    "print(\"dataset loading complete\")\n",
    "\n",
    "dataloader1, dataloader2 = dataloader.chunk(2, dim=0)\n",
    "\n",
    "# print(dataloader.shape)\n",
    "\n",
    "input_ids = dataloader.to(device)\n",
    "model_weights = model.state_dict()\n",
    "\n",
    "if model_param == \"2.8b\":\n",
    "    layer_num = 64\n",
    "    d_model = 2560\n",
    "elif model_param == \"130m\":\n",
    "    layer_num = 24\n",
    "    d_model = 768\n",
    "elif model_param == \"370m\":\n",
    "    layer_num = 48\n",
    "    d_model = 1024\n",
    "elif model_param == \"790m\":\n",
    "    layer_num = 48\n",
    "    d_model = 1536\n",
    "elif model_param == \"1.4b\":\n",
    "    layer_num = 48\n",
    "    d_model = 2048\n",
    "\n",
    "d_state = 16\n",
    "dt_rank = model_weights['backbone.layers.0.mixer.x_proj.weight'].shape[0] - d_state*2\n",
    "d_inner = d_model * 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer_in_proj_weights = ['backbone.layers.{0}.mixer.in_proj.weight'.format(i) for i in range(layer_num)]\n",
    "mixer_out_proj_weights = ['backbone.layers.{0}.mixer.out_proj.weight'.format(i) for i in range(layer_num)]\n",
    "mixer_A_log_weights=['backbone.layers.{0}.mixer.A_log'.format(i) for i in range(layer_num)]         \n",
    "mixer_conv1d_weights=['backbone.layers.{0}.mixer.conv1d.weight'.format(i) for i in range (layer_num)]\n",
    "mixer_conv1d_bias=['backbone.layers.{0}.mixer.conv1d.bias'.format(i) for i in range (layer_num)]\n",
    "mixer_dt_proj_weights=['backbone.layers.{0}.mixer.dt_proj.weight'.format(i) for i in range(layer_num)]\n",
    "mixer_dt_proj_bias=['backbone.layers.{0}.mixer.dt_proj.bias'.format(i) for i in range(layer_num)]\n",
    "mixer_x_proj_weights=['backbone.layers.{0}.mixer.x_proj.weight'.format(i) for i in range(layer_num)]\n",
    "norm_weights = ['backbone.layers.{0}.norm.weight'.format(i) for i in range(layer_num)]\n",
    "mixer_D = ['backbone.layers.{0}.mixer.D'.format(i) for i in range(layer_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = nn.Embedding.from_pretrained(model_weights['backbone.embedding.weight'])\n",
    "embedded_input = embedding_layer(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_state = embedded_input\n",
    "prev_residual = torch.empty(nsamples,seqlen,d_model).to(device=device_num)\n",
    "# print(prev_residual.shape)\n",
    "norm_cls = RMSNorm(hidden_size=d_model, device=device, dtype=dtype)\n",
    "\n",
    "for i in range(layer_num):\n",
    "# for i in range(1):\n",
    "    with torch.no_grad():\n",
    "        residual = hidden_state + prev_residual\n",
    "\n",
    "        norm_cls.weight = nn.Parameter(model_weights[norm_weights[i]])\n",
    "        normalized_hidden_input = norm_cls(hidden_state)\n",
    "\n",
    "        # print(model_weights[mixer_in_proj_weights[i]].shape)\n",
    "        # print(model_weights[mixer_in_proj_weights[i]])\n",
    "        if prune_in_proj == True:\n",
    "            model_weights[mixer_in_proj_weights[i]] = wanda(rearrange(normalized_hidden_input,\"b l d -> (b l) d\"), model_weights[mixer_in_proj_weights[i]],sparsity_ratio, prune_n)\n",
    "        # print(wanda_in_proj.shape)\n",
    "        # print(wanda_in_proj)\n",
    "\n",
    "        # print(torch.cuda.memory_allocated(device))\n",
    "        # print(torch.cuda.memory_reserved(device))\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        xz = normalized_hidden_input @ model_weights[mixer_in_proj_weights[i]].T\n",
    "\n",
    "        # print(xz.shape)\n",
    "        # print(xz)\n",
    "        x, z = xz.chunk(2, dim=2)\n",
    "        # print(x.shape)\n",
    "        # print(z.shape)\n",
    "        # print(model_weights[mixer_conv1d_weights[i]].shape)\n",
    "        # print(model_weights[mixer_conv1d_bias[i]].shape)   \n",
    "\n",
    "        model_weights[mixer_conv1d_weights[i]] = rearrange(model_weights[mixer_conv1d_weights[i]], \"b l d -> (b l) d\")\n",
    "        \n",
    "        # print(tmp_conv1d_weights.shape)\n",
    "        # print(tmp_conv1d_wei...\n",
    "model.save_pretrained(os.path.expanduser(args.store_address))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSED499-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
